# SVO2: 适应于单目-多目相机系统的半直接法视觉里程计

 **Author:** [方川]

 **Link:** [https://zhuanlan.zhihu.com/p/514076658]

标题：SVO:Semidirect Visual Odometry for Monocular and Multi-Camera Systems

作者：Forster Christian, Zhang Zichao, Gassner Michael, Werlberger Manuel, Scaramuzza Davide

来源：TRO 2017

今天我们要精读的文章事来自UZH的svo2。这篇工作在2016就发表了, 但是源码在2021才释出. 本文提出的半直接视觉里程计方法很好的结合了直接法的精度、鲁棒性， 和特征点法能够保证计算效率、全局一致性的优点, 在运行速度和全局精度两个指标上取得了很好的结果. 同时, 本文提出了一种鲁棒的深度估计算法, 使得系统可以在较弱纹理区域也能正常运行. 本文方法在若果数据集上都去了sota的表现.

## 摘要:  
直接法视觉里程计的优势得到普遍认可, 但是在运行速度、全局一致性等指标上明显劣于特征点法视觉里程计. 借鉴两种方法的优点, 我们提出了半直接法视觉里程计: 使用直接法跟踪梯度较大的图像区域, 使用特征点法优化地图点和相机位姿. 同时, 本文提出了一种基于概率的鲁棒的深度估计算法, 使得我们在低纹理、重复纹理场景中也能很好的实现跟踪. 本文方法可以拓展到广角相机、多相机系统, 同时可以将其他形式的运动先验信息(imu/gps/wheel-odometry)加到系统中. 在多个数据集上测试验证了本文方法的优越性.

## 算法流程:  
本文方法的整体框图如下:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-8cf076e733e48a08d469795b3506f81e_1440w.jpg)  
  


运动估计/跟踪线程使用本文提出的半直接法来完成运动估计, 具体分为三步:

* 稀疏直接法把当前帧图像与上一帧图像对齐, 估计帧间运动;
* 从上一个关键帧中重投影地图点, 使用重投影像素块对齐当前帧的2D特征点, 优化帧间运动运动造成的漂移;
* 最小二乘优化相机位姿和地图点, 消除第二步2D特征对齐引入的对极误差;

建图线程使用本文提出的深度估计滤波器对每个关键帧上的特征点/边进行深度估计, 当滤波器的方差低于阈值时则认为该点/边的深度稳定了，立即构建一个地图点.

**Notation**:

相机 $C$ ​在时刻 $k$ ​处的灰度图记为 $I_k^c:\Omega^c \subset \mathbb R^2$ ​, ​ $\Omega^c$ 表示图像域. 空间一点​ $\mathbb \rho \in \mathbb R^3$ 通过相机投影模型 $\mathbb u = \pi (\mathbb \rho)$ ​映射到图像坐标 $u$ ​. 给定图像坐标 $\mathbb u \in \mathcal R^c_k$ ​以及它对应的逆深度​ $\rho$ , 则它对应的空间点可以通过反投影得到 $\mathbb{\rho} = \pi^{-1}_{\rho} (\mathbb u)$ ​, 这里是假设​ $ \mathcal R^c_k$ 区域内的深度值是已知的. 第​ $k^{th}$ 帧图像的位姿记为 $T_{kw} \in SE(3)$ ​, 表示将世界坐标系下的点 $_w \mathbb \rho $ ​变换到当前帧相机坐标系​: $_k \mathbb \rho = T_{kw} \cdot _w \mathbb \rho $

### 运动估计  
运动估计过程中, 我们假设已知深度信息, 比如要用到的角点/边的深度值.

**A. 稀疏图像对齐**:

类似于直接法LSD-SLAM, 本方法中的图像对齐算法也是最小化光度误差, 但是本文图像对齐算法只对地图点对应的角点所在的图像块最小化光度误差. 估计帧间运动​ $T_{kk-1} = T_{B_kB_{k-1}}$ 的目标函数为:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-97b3f47c2468c0fc929eaad0121fd426_1440w.png)  
光度误差​ $r_{I^c_u}$ 是地图点 $\mathbf{ \rho_u}$ ​在相邻图像帧​ $I^c_{k-1}$ 、 $I^c_{k}$ ​的观测的强度误差:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-cd26d09178c699984fde84b01c8005d9_1440w.png)  
因此, 本文方法在初始化时仍然需要提取稀疏特征点, 而不是像LSD-SLAM那样直接提取图像的灰度梯度较大的区域. 这里需要解释清楚的是: dense方法是指利用参考图像帧上所有像素点和深度信息来做帧间运动估计, semi-dense方法指的是利用图像上像素梯度较大的像素点来做帧间运动估计, 而本文是只使用一些稀疏的角点/边来进行帧间运动估计.

**B. 2D特征点对齐**:

考虑到帧间运动估计极容易产生漂移, 因此我们需要把当前帧与历史帧再做一次对齐来消除漂移. 这里引入关键帧策略, 关键帧上会将地图点(事先提取特征点(FAST), 利用图像位姿和深度信息反投影得到)投影到当前帧, 然后把这些重投影的特征点扩大为8x8的像素块, 特征点对齐问题转换为2D像素块的对齐优化问题. 像素块的对齐过程考虑了这两帧图像之间的相对位姿变换引起的二维图像的仿射变换, 最小化像素块中的梯度直方图误差来更新当前帧上的特征点位置 $\mathbf {u'^*}$ ​; 对corner feature, 最小二乘优化目标函数如公式(4): 其中 $\mathbb u'$ ​为关键帧 $r$ ​的地图点在当前帧​ $k$ 上的的投影点, ​ $\mathcal P$ 为以​ $\mathbb u'$ 为中心的一个像素块, ​ $\Delta {\mathbb u}$ 为计算​ $\mathcal P$ 中像素梯度和的一个迭代算子:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-d00f1484e415a039bc83c62955f7ab8e_1440w.jpg)  
  


Edge feature的最小二乘优化目标函数公式(5). 我们减少edge特征的维度为1维, 使edge特征只沿着edge法向量​的方向优化:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-317f3965a37f0ef0089c1a4d00ba7ab0_1440w.jpg)  
![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-9c045cfffc4986538712672c2e9f62e7_1440w.jpg)  
  


  


**C. 优化相机位姿和地图点**

通过2D特征点对齐, 我们建立了了亚像素级的特征点对应关系feature correspondences. 由于步骤B改变了当前帧上特征点的"观测位置"(通过重投影地图点得到, 并非是提取得到的), 因此还需要进一步优化当前帧位姿和地图点 $\chi = \{T_{kw}, \rho_i\}$ ​:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-41ae17ceeb2e574fb4f1f24804dbf0b9_1440w.jpg)  
  


### 环境建图:  
**A. 深度滤波器**

在运动估计环节中, 我们用到了每个关键帧上的特征点, 并且假设这些特征点的深度是已知的. 但是对于关键帧上新提取的特征点, 它的深度是对其在多个图像上的观测进行递归贝叶斯滤波得到的. 

关键帧的选取策略是当corner和edge feature的跟踪长度小于某一阈值时, 就把当前帧选做关键帧. 所以每个depth filter其实属于某一个关键帧上的一个特征点, depth filter的逆深度不确定度初始化为很大的一个值. 我们称该特征点的像素块为reference patch, 由于新提取的特征点在其他普通帧/关键帧上并没有事先提取, 所以需要在这些已知相对位姿​ $\{I_k, T_{kr}\}$ 的关键帧/普通帧上, 根据对极线来搜索有最小光度误差的patch correspondence, 然后三角化该特征点得到深度值 $\tilde \rho_i^k$ ​ 来送入depth filter. 

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-c04b93a1772fb9f22fa803f2972230f9_1440w.jpg)  
  


当有足够多的depth estimation送入depth filter后, depth filter的不确定值低于一定阈值后, 我们就将该特征点三角化, 用于运动估计环节. 对于edge feature使用同样的方法来计算深度, 但是不考虑法线方向与对极线方向平行的edge feature.

理想情况下, 我们希望使用类似蒙特卡洛的方法来估计特征点逆深度真值, 但是这样复杂度太高. 如Fig.6所示, 我们对比了用Gaussian分布和Gaussian+Uniform分布描述逆深度​的效果区别:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-e8198488bd6a540267f09d6be706bda4_1440w.jpg)  
  


具体的, Gaussian+Uniform分布模型包含逆深度变量 $\rho$ ​和内点概率​ $r$ :

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-03200af3526882224d060e016716f3d6_1440w.png)  
  


这一章节的理论部分可以参考<<Video-based, Real-Time Multi View Stereo>>的"Probabilitic depth sensor"小结.

Fig.6和Fig.7的实验都证明了Gaussian+Uniform分布模型的depth filter能够更好的应对噪声外点:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-c866d5d8c6218fabaa655e0408a9d36c_1440w.jpg)  
  


  


**B. 多相机系统**

由于我们定义了body坐标系, 假设多相机系统 $c \in \mathbf C$ 的任一台相机​的外参 $T_{CB}$ ​已知, 那么在运动估计环节我们只需要把每个相机的光度误差和重投影误差加入到优化目标函数中. 比如在稀疏图像对齐步骤中, 把公式(1)改写为公式(11):

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-457c06da295eb7b755816b9c063d781d_1440w.png)  
在优化相机位姿和地图点步骤同理.

  


### 运动先验  
在一些快速运动以及无纹理场景, 我们支持加入一些运动先验来应对视觉运动估计环节出错的问题. 如公式(12)所示, 我们只需要把运动先验(IMU或者GPS)加入到帧间运动估计的目标函数中即可:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-7493e882d3917b4ed4fec946fb3bea48_1440w.jpg)  
  


  


## 实现细节:  
A. 初始化

系统的初始化使用前两帧关键帧, 提取稀疏特征点(FAST), 并完成初始化地图. 对于多目相机, 初始地图的位置由两两双目匹配的均值确定.

B. 稀疏图像对齐

图像对齐过程, 我们采用4x4的像素块来完成帧间运动的估计. 为了应对剧烈运动, 我们设计了一种coarse-to-fine的图像对齐策略, 本质就是不同分辨率的图像金字塔, 这里我们使用了5 level金字塔, 实际上在第3层就结束图像对齐过程的计算. 

C. 特征对齐

特征对齐阶段, 我们使用了8x8的像素块. 考虑到参考关键帧可能距离当前关键帧较远, 我们设计了一个仿射变换矩阵来处理照明条件的变化. 整个算法运行时, 我们限制特征点数量<180.

D.建图

在建图过程, 我们把图像分割成若干个32x32的单元, 每个关键帧上, 我们只对每个单元中一个FAST角点初始化一个深度估计滤波器. 对于没有提取到FAST角点的单元, 我们去提取梯度最大的边特征并且初始化深度估计滤波器. 深度估计需要匹配前后两帧特征点/边, 由于我们已知帧间运动, 因此我们这里只在对极线附近搜索特征点/边. 这里我们使用了一个8x8大小的像素块来进行对极搜索.

## 实验结果:  
我们首先在合成数据集上测试了本文提出的图像对齐算法, 随后在22个不同数据集序列上验证了整个算法流程, 并且与其他sota算法对比.

A. 稀疏、半稠密、稠密的图像对齐算法测试结果:

我们在Urban Canyon数据集上测试本文提出的稀疏图像对齐算法、半稠密图像对齐算法、稠密图像对齐算法. 我们任选一帧 $I_r$ ​作为参考帧, 计算其后60帧图像​ $k \in \{r+1,…,r+60\}$ 相对于参考帧的相对位姿 $T_{rk}$ ​, 两帧间距0.2m, 每帧图像的平均深度约为12.4m. 对齐算法在每个图像对​上运行800次, 并且施加了一定的初始噪声. 相对位姿的估计值与真值偏差小于0.1m的则认为是收敛的估计结果.

对于本文提出的稀疏图像对齐算法, 我们在参考帧​ $I_r$ 中提取了100个FAST角点并且根据已知深度三角化出角点对应的地图点. 我们测试了不同的像素块大小:1x1到5x5的消融实验，并且和半稠密法:LSD和稠密法DTAM的图像对齐结果对比, 对比结果如图所示:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-0b42d39354de171ea530c623f54df344_1440w.jpg)  
从Fig 11可以看出稀疏图像对齐法在​距离​较远时精度远差于半稠密法, 所以我们只将稀疏图像对齐算法应用于 $I_k$ ​与​ $I_{k+1}$ 之间, 而不是应用于关键帧上.

B. 在真实/合成数据集上整体算法测试

我们把本文提出的算法与其他sota算法在EuRoC、TUM、ICL-NUIM数据集上进行测试对比.

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-d1bc6561f66b53350d391adea78b4428_1440w.jpg)  
EuRoC上的测试结果表明: svo在双目数据集上能够取得较好的精度, 但是在单目数据集上精度劣于ORB-SLAM/DSO. 但是从运行时效率上, svo更胜一筹:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-f447f29456f83868fd6a1a45f7887be7_1440w.jpg)  
  


![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-a0cb00a16dcaf0acc78b893d411405f9_1440w.jpg)  
  


SVO运行速度快是因为它的图像前端并没有提取特征点和描述子, 而只是在关键帧上提取一定数量的FAST.

TUM数据集上测试结果发现LSD-SLAM/ORB-SLAM都优于svo, 可能是因为他们开启了回环检测的原因.

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-61ce131a6cf8a1f8c8ca9d9793c885e7_1440w.jpg)  
  


ICL-NUIM数据集是一个合成的RGB-D slam数据集， 该数据集因为有很多纯旋转的运动以及比较困难的纹理场景, 所以比较具有挑战性. 我们在4段轨迹上运行了5次不同的vo算法, 统计对比如下表:

![]((20220515)SVO2_适应于单目-多目相机系统的半直接法视觉里程计_方川/v2-b30facad47dfab674eb7e134aa81c884_1440w.jpg)  
  


## 讨论:  
A. Efficiency

svo不需要提取特征, 直接通过对齐像素块的梯度值来估计帧间运动, 特别适用于高帧率的相机.

B. Accuracy

svo通过直接对齐2d feature来获得亚像素级精度, 然后基于重投影误差优化地图点和相机位姿. 对于精度要求不高的额应用场景, 我们只需要对当前帧图像位姿进行优化, 否则就对所有历史帧进行BA优化.

C. Robustness

因为svo不提取特征点, 所以可以很好的应对纹理较少或者重复纹理的场景, 本文提出的深度估计滤波方法也比传统的多视角重建地图点的方法要好，因为滤波方法在喂入更多的观测数据后会更加准确并且对outlier不敏感.

